---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: dc-kafka
  namespace: databuff
spec:
  selector:
    matchLabels:
      app: dc-kafka
  serviceName: "dc-kafka-svc"
  replicas: 3
  updateStrategy:
    type: RollingUpdate
  podManagementPolicy: Parallel
  template:
    metadata:
      labels:
        app: dc-kafka
    spec:
      imagePullSecrets:
        - name: docker-reg-secret
      containers:
        - name: kafka
          imagePullPolicy: Always
          image: 192.168.50.212/library/kafka:v2.13
          resources:
            requests:
              memory: "1000Mi"
              cpu: "1"
          env:
            - name: SERVERS                      # 要确保 SERVERS 设置的值与副本数一致
              value: "3"
            - name: KAFKA_LISTENERS
              value: "PLAINTEXT://:9092"
            - name: KAFKA_ZOOKEEPER_CONNECT      # 设置 Zookeeper 连接地址
              value: "dc-zk-inner-svc.databuff.svc.cluster.local:2181"
            - name: KAFKA_PORT
              value: "9092"
            - name: KAFKA_MESSAGE_MAX_BYTES
              value: "20000000"
            - name: BROKER_ID_COMMAND            # 这个变量用于在容器内部生成一个 broker id
              value: "hostname | awk -F'-' '{print $NF}'"
          volumeMounts:
            - name: kafka-log                    # 只需要将 kafka 的 log 目录持久化存储
              mountPath: /kafka
              subPath: kafka-cluster-log
            - name: data-conf
              mountPath: /etc/localtime
      volumes:
        - name: kafka-log
          persistentVolumeClaim:
            claimName: dc-zk-kafka-pvc
        - name: data-conf
          hostPath:
            path: /usr/share/zoneinfo/Asia/Shanghai