{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch('192.168.50.98:19201')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weijunfei/anaconda3/lib/python3.7/site-packages/elasticsearch/connection/base.py:190: ElasticsearchDeprecationWarning: [types removal] Specifying types in bulk requests is deprecated.\n",
      "  warnings.warn(message, category=ElasticsearchDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "with open('./realTweets_json/numenta_Twitter_volume_AAPL.json','r',encoding='utf8')as fp:\n",
    "    json_data = json.load(fp)\n",
    "\n",
    "#批量更新也可以采用如下的方式进行json拼装，最后写入\n",
    "ACTIONS = []\n",
    "for line in json_data:\n",
    "    action = {\n",
    "        \"_index\": 'dc_est_data',\n",
    "        \"_type\": '_doc',\n",
    "        \"_source\": {\n",
    "            \"itemid\": 'ueba_demo_5',\n",
    "            \"timestamp\": line['timestamp'],\n",
    "            \"value\": line['value'],\n",
    "            \"score\": line['anomaly_score'],\n",
    "            \"level\": 3 if line['anomaly_score']>0.65076904296875 else 1}\n",
    "    }\n",
    "    ACTIONS.append(action)\n",
    "success, _ = helpers.bulk(es, ACTIONS, index='dc_est', raise_on_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 批量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(file, itemid):\n",
    "    with open(file,'r',encoding='utf8')as fp:\n",
    "        json_data = json.load(fp)\n",
    " \n",
    " #批量更新也可以采用如下的方式进行json拼装，最后写入\n",
    "    ACTIONS = []\n",
    "    for line in json_data:\n",
    "        action = {\n",
    "            \"_index\": 'dc_est_data',\n",
    "            \"_type\": '_doc',\n",
    "            \"_source\": {\n",
    "                \"itemid\": itemid,\n",
    "                \"timestamp\": line['timestamp'],\n",
    "                \"value\": line['value'],\n",
    "                \"score\": line['anomaly_score'],\n",
    "                \"level\": 3 if line['anomaly_score']>0.65076904296875 else 1},\n",
    "        }\n",
    "        ACTIONS.append(action)\n",
    "    success, _ = helpers.bulk(es, ACTIONS, index='dc_est', raise_on_error=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "files = glob('./realTweets_json/*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit(files[1], 'ueba_demo_6')\n",
    "submit(files[2], 'ueba_demo_7')\n",
    "submit(files[3], 'ueba_demo_8')\n",
    "submit(files[4], 'ueba_demo_9')\n",
    "submit(files[5], 'ueba_demo_10')\n",
    "submit(files[6], 'ueba_demo_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "artificialWithAnomaly = glob('./artificialWithAnomaly_json/*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit(artificialWithAnomaly[0], 'ueba_demo_2')\n",
    "submit(artificialWithAnomaly[1], 'ueba_demo_3')\n",
    "submit(artificialWithAnomaly[2], 'ueba_demo_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_entity(file, itemid, entity):\n",
    "    with open(file,'r',encoding='utf8')as fp:\n",
    "        json_data = json.load(fp)\n",
    " \n",
    " #批量更新也可以采用如下的方式进行json拼装，最后写入\n",
    "    ACTIONS = []\n",
    "    for line in json_data:\n",
    "        action = {\n",
    "            \"_index\": 'dc_est_data',\n",
    "            \"_type\": '_doc',\n",
    "            \"_source\": {\n",
    "                \"itemid\": itemid,\n",
    "                \"entity\": entity,\n",
    "                \"timestamp\": line['timestamp'],\n",
    "                \"value\": line['value'],\n",
    "                \"score\": line['anomaly_score'],\n",
    "                \"level\": 3 if line['anomaly_score']>0.65076904296875 else 1},\n",
    "        }\n",
    "        ACTIONS.append(action)\n",
    "    success, _ = helpers.bulk(es, ACTIONS, index='dc_est', raise_on_error=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_entity(artificialWithAnomaly[3], 'pjme', '192.168.50.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = [{'user':'AKW0167', \n",
    "              'score':80, \n",
    "              'scenario':'敏感数据泄露', \n",
    "              'events':'{\"2021-09-13 18:27:36\": \"aaaaaaaaaaaaaaaa\",\"2021-09-13 18:24:36\": \"aaaaaaaaaaaaaaaa\"}', \n",
    "              'date': '2021-09-13 17:00:00'},\n",
    "            {'user':'AKW0167', \n",
    "              'score':70, \n",
    "              'scenario':'私人文件盗取', \n",
    "              'events':'{\"2021-09-13 18:27:36\": \"aaaaaaaaaaaaaaaa\",\"2021-09-13 18:24:36\": \"aaaaaaaaaaaaaaaa\"}', \n",
    "              'date': '2021-09-13 17:00:00'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#批量更新也可以采用如下的方式进行json拼装，最后写入\n",
    "ACTIONS = []\n",
    "for line in json_data:\n",
    "    action = {\n",
    "        \"_index\": 'dc_emp_data',\n",
    "        \"_type\": '_doc',\n",
    "        \"_source\": {\n",
    "            \"user\": line['user'],\n",
    "            \"score\": line['score'],\n",
    "            \"scenario\": line['scenario'],\n",
    "            \"events\": line['events'],\n",
    "            \"datetime\": line['date']}\n",
    "    }\n",
    "    ACTIONS.append(action)\n",
    "success, _ = helpers.bulk(es, ACTIONS, index='dc_emp_data', raise_on_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
